{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(url,**kwargs):\n",
    "    url_params = \"?\"+urllib.parse.urlencode(kwargs)\n",
    "    acctual_url = urllib.parse.urljoin(url,url_params)\n",
    "    response = requests.get(acctual_url)\n",
    "    num_pages = response.json()[\"last_page\"]\n",
    "    data = []\n",
    "    for page in range(1,num_pages +1):\n",
    "        url_current = acctual_url + f\"&page={page}\"\n",
    "        response = requests.get(url_current)\n",
    "        data += response.json()[\"data\"][\"data\"]\n",
    "\n",
    "    flatten_data = [flatten_json(d) for d in data]\n",
    "    return pd.DataFrame(flatten_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        #elif type(x) is list:\n",
    "        #    i = 0\n",
    "        #    for a in x:\n",
    "        #        flatten(a, name + str(i) + '_')\n",
    "        #       i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_tuple(data):\n",
    "    if any(data):\n",
    "        if len(data) == 1:\n",
    "            return tuple(data)[0]\n",
    "        return tuple(data)\n",
    "    else:\n",
    "        np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_characteristica = \"http://0.0.0.0:8000/api/v1/characteristica_elastic/\"\n",
    "url_outputs = \"http://0.0.0.0:8000/api/v1/outputs_elastic/\"\n",
    "url_timecourses = \"http://0.0.0.0:8000/api/v1/timecourses_elastic/\"\n",
    "url_interventions = \"http://0.0.0.0:8000/api/v1/interventions_elastic/\"\n",
    "url_individuals = \"http://0.0.0.0:8000/api/v1/individuals_elastic/\"\n",
    "url_groups = \"http://0.0.0.0:8000/api/v1/groups_elastic/\"\n",
    "base_params = {\"format\":\"json\", \"final\":\"true\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load output data\n",
    "df_outputs = get_data(url_outputs,**base_params)\n",
    "# drop not important columnns (cleaning)\n",
    "df_outputs = df_outputs.dropna(how=\"all\",axis=1).drop([\"final\",\"individual_name\",\"group_name\"],axis=1)\n",
    "# reduce the content of interventions to a lift of pk values of the internventions\n",
    "df_outputs[\"interventions\"] = df_outputs[\"interventions\"].apply(lambda interventions: [x[\"pk\"] for x in interventions])\n",
    "# unstack outputs by the list of pks in the interventions column\n",
    "lst_col = 'interventions'\n",
    "df_outputs = pd.DataFrame({col:np.repeat(df_outputs[col].values, df_outputs[lst_col].str.len()) for col in df_outputs.columns.difference([lst_col])}).assign(**{lst_col:np.concatenate(df_outputs[lst_col].values)})[df_outputs.columns.tolist()]\n",
    "# change interventions pks format to int\n",
    "df_outputs.interventions = df_outputs.interventions.astype(int)\n",
    "# sort columns by number of not nan values\n",
    "df_outputs = df_outputs[df_outputs.apply(lambda x: x.count()).sort_values(ascending=False).index]\n",
    "df_outputs.set_index(\"pk\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_outputs.to_csv(\"outputs.tsv\", sep=\"\\t\")\n",
    "df_outputs.to_excel(\"outputs.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timecourses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load output data\n",
    "df_timecourses = get_data(url_timecourses,**base_params)\n",
    "# drop not important columnns (cleaning)\n",
    "df_timecourses = df_timecourses.dropna(how=\"all\",axis=1).drop([\"final\",\"individual_name\",\"group_name\"],axis=1)\n",
    "# reduce the content of interventions to a lift of pk values of the internventions\n",
    "df_timecourses[\"interventions\"] = df_timecourses[\"interventions\"].apply(lambda interventions: [x[\"pk\"] for x in interventions])\n",
    "# unstack outputs by the list of pks in the interventions column\n",
    "lst_col = 'interventions'\n",
    "df_timecourses = pd.DataFrame({col:np.repeat(df_timecourses[col].values, df_timecourses[lst_col].str.len()) for col in df_timecourses.columns.difference([lst_col])}).assign(**{lst_col:np.concatenate(df_timecourses[lst_col].values)})[df_timecourses.columns.tolist()]\n",
    "# change interventions pks format to int\n",
    "df_timecourses.interventions = df_timecourses.interventions.astype(int)\n",
    "# sort columns by number of not nan values\n",
    "df_timecourses = df_timecourses[df_timecourses.apply(lambda x: x.count()).sort_values(ascending=False).index]\n",
    "df_timecourses.set_index(\"pk\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timecourses.to_csv(\"timecourses.tsv\", sep=\"\\t\")\n",
    "df_timecourses.to_excel(\"timecourses.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load output data\n",
    "df_interventions = get_data(url_interventions,**base_params)\n",
    "# drop not important columnns (cleaning)\n",
    "df_interventions = df_interventions.dropna(how=\"all\",axis=1).drop(\"final\",axis=1)\n",
    "# sort columns by number of not nan values\n",
    "df_interventions = df_interventions[df_interventions.apply(lambda x: x.count()).sort_values(ascending=False).index]\n",
    "df_interventions.set_index(\"pk\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_interventions.to_csv(\"interventions.tsv\", sep=\"\\t\")\n",
    "df_interventions.to_excel(\"interventions.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load individual and group data\n",
    "base_params = {\"format\":\"json\"} \n",
    "df_individuals = get_data(url_individuals,**base_params)\n",
    "df_groups = get_data(url_groups,**base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_characteristica(df_subject):\n",
    "    lst_col = 'characteristica_all_final'\n",
    "    df_subject = pd.DataFrame({col:np.repeat(df_subject[col].values, df_subject[lst_col].str.len()) for col in df_subject.columns.difference([lst_col])}).assign(**{lst_col:np.concatenate(df_subject[lst_col].values)})[df_subject.columns.tolist()]\n",
    "    df = df_subject[\"characteristica_all_final\"].apply(pd.Series)\n",
    "    df[\"study\"] = df_subject[\"study_name\"]\n",
    "    df.drop([\"pk\", \"ctype\"], axis=1,inplace=True)\n",
    "    df[\"subject_pk\"] = df_subject[\"pk\"]\n",
    "    df[\"subject_name\"] = df_subject[\"name\"]\n",
    "\n",
    "    df = df.pivot_table(index=[\"study\",\"subject_pk\",\"subject_name\"], columns=[\"category\"], aggfunc=my_tuple)\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    df = df[df.groupby(level=0, axis=0).count().sum().max(level=0).sort_values(ascending=False).index]\n",
    "    df.dropna(how=\"all\", axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_groups_individuals(df_groups_pivot,df_individuals_pivot):\n",
    "    df = pd.concat([df_groups_pivot,df_individuals_pivot], keys=[\"group\",\"individual\"])   \n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"level_0\":\"subject_type\"},inplace=True)\n",
    "    df.set_index([\"study\",\"subject_type\",\"subject_pk\",\"subject_name\"], inplace=True)\n",
    "    df = df[df.groupby(level=0, axis=0).count().sum().max(level=0).sort_values(ascending=False).index]\n",
    "    df = df.dropna(how=\"all\", axis=1)\n",
    "    return  df.sort_index()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_individuals_pivot = preprocess_characteristica(df_individuals)\n",
    "df_groups_pivot = preprocess_characteristica(df_groups)\n",
    "df_all_subjects = merge_groups_individuals(df_groups_pivot,df_individuals_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>characteristica_all_final</th>\n",
       "      <th>count</th>\n",
       "      <th>name</th>\n",
       "      <th>parent</th>\n",
       "      <th>parent_name</th>\n",
       "      <th>parent_pk</th>\n",
       "      <th>pk</th>\n",
       "      <th>study_name</th>\n",
       "      <th>study_pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'pk': 1899, 'count': 4, 'category': 'age', '...</td>\n",
       "      <td>4</td>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195</td>\n",
       "      <td>Bonati1982</td>\n",
       "      <td>7083737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           characteristica_all_final  count name  parent  \\\n",
       "0  [{'pk': 1899, 'count': 4, 'category': 'age', '...      4   S1     NaN   \n",
       "\n",
       "  parent_name  parent_pk   pk  study_name study_pk  \n",
       "0         NaN        NaN  195  Bonati1982  7083737  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups[df_groups[\"study_name\"]==\"Bonati1982\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_groups_pivot.to_excel(\"groups.xlsx\")\n",
    "df_groups_pivot.to_csv(\"groups.tsv\", sep=\"\\t\")\n",
    "\n",
    "df_individuals_pivot.to_excel(\"individuals.xlsx\")\n",
    "df_individuals_pivot.to_csv(\"individuals.tsv\", sep=\"\\t\")\n",
    "\n",
    "df_all_subjects.to_csv(\"all_subjects.tsv\", sep=\"\\t\")\n",
    "df_all_subjects.to_excel(\"all_subjects.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkdb_analysis",
   "language": "python",
   "name": "pkdb_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
